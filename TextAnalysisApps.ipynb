{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from janome.tokenizer import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_tokenizer = Tokenizer()\n",
    "def ja_tokenize(text):\n",
    "    res=[]\n",
    "    lines=text.split('\\n')\n",
    "    for line in lines:\n",
    "        malist = ja_tokenizer.tokenize(line)\n",
    "        for tok in malist:\n",
    "            ps=tok.part_of_speech.split(\",\")[0]\n",
    "            if not ps in ['名詞', '動詞', '形容詞', '形容動詞']: continue\n",
    "            w=tok.base_form\n",
    "            if w==\"*\" or w==\"\": w=tok.surface\n",
    "            if w==\"\" or w==\"\\n\": continue\n",
    "            res.append(w)\n",
    "        res.append(\"\\n\")\n",
    "    return res\n",
    "\n",
    "#未知データ用関数\n",
    "def predicted_group(s, answer, model):\n",
    "    pred = model.predict([s])\n",
    "    return answer[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# a = pd.read_excel('training.xlsx', sheet_name = 'メインシート', encoding='shift-jis')\n",
    "a = pd.read_excel('EI_learning_data.xlsx', sheet_name = 'MCOR', encoding='shift-jis')\n",
    "b = a[['件名/問い合わせ内容（状況）','Level1']]\n",
    "b['Answer'] = b['Level1'].map({'CAx':1, 'RCD':2, 'ハーネス':3, 'その他':4, '出図管理':5, 'VSS':6})\n",
    "b = b.dropna(subset=['件名/問い合わせ内容（状況）'])\n",
    "b = b.reset_index(drop = True)\n",
    "b['Answer'] = b['Answer'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(CountVectorizer(),MultinomialNB(alpha=0.1,fit_prior = 'True'))\n",
    "model2 = make_pipeline(TfidfVectorizer(),MultinomialNB(alpha=0.1,fit_prior = 'True'))\n",
    "model3 = make_pipeline(CountVectorizer(),svm.SVC(gamma='scale'))\n",
    "model4 = make_pipeline(TfidfVectorizer(),svm.SVC(gamma='scale'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, labels_train, labels_test = train_test_split(b['件名/問い合わせ内容（状況）'], b['Answer'], train_size=0.70, random_state=10)\n",
    "\n",
    "cvs = cross_val_score(model, b['件名/問い合わせ内容（状況）'],b['Answer'],cv=5)\n",
    "cvs2 = cross_val_score(model2, b['件名/問い合わせ内容（状況）'],b['Answer'],cv=5)\n",
    "cvs3 = cross_val_score(model3, b['件名/問い合わせ内容（状況）'],b['Answer'],cv=5)\n",
    "cvs4 = cross_val_score(model4, b['件名/問い合わせ内容（状況）'],b['Answer'],cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81390135 0.82882883 0.77477477 0.8018018  0.75395034]\n",
      "0.7946514178594674\n",
      "[0.81165919 0.82882883 0.79054054 0.80405405 0.77200903]\n",
      "0.8014183291187816\n",
      "[0.80269058 0.81756757 0.78153153 0.8018018  0.81038375]\n",
      "0.8027950462077744\n",
      "[0.80493274 0.82207207 0.76576577 0.80855856 0.8013544 ]\n",
      "0.8005367067256548\n"
     ]
    }
   ],
   "source": [
    "# clf = MultinomialNB(alpha = 0.1, fit_prior='True')\n",
    "print(cvs,cvs.mean())\n",
    "print(cvs2,cvs2.mean())\n",
    "print(cvs3,cvs3.mean())\n",
    "print(cvs4,cvs4.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.fit(data_train,labels_train)\n",
    "b['Predict'] = model4.predict(b['件名/問い合わせ内容（状況）'])\n",
    "b.to_csv('EI_HELPDESK_Classification_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer=ja_tokenize)\n",
    "tfidf = TfidfVectorizer(analyzer=ja_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = count_vectorizer.fit_transform(b['件名/問い合わせ内容（状況）'].astype(str))\n",
    "s = mat.toarray().tolist()\n",
    "b['CV'] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ベクトル化したデータを抽出\n",
    "# mat = tfidf.fit_transform(b['件名/問い合わせ内容（状況）'].astype(str))\n",
    "# s = mat.toarray().tolist()\n",
    "# b['tfidf'] = s\n",
    "# b.head()\n",
    "# # b.to_csv('EI_vectorize_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(CountVectorizer(),MultinomialNB(alpha=0.1,fit_prior = 'True'))\n",
    "model2 = make_pipeline(TfidfVectorizer(),MultinomialNB(alpha=0.1,fit_prior = 'True'))\n",
    "model3 = make_pipeline(CountVectorizer(),svm.SVC(gamma='scale'))\n",
    "model4 = make_pipeline(TfidfVectorizer(),svm.SVC(gamma='scale'))\n",
    "\n",
    "model.fit(b['件名/問い合わせ内容（状況）'],b['Answer'])\n",
    "model2.fit(b['件名/問い合わせ内容（状況）'],b['Answer'])\n",
    "model3.fit(b['件名/問い合わせ内容（状況）'],b['Answer'])\n",
    "model4.fit(b['件名/問い合わせ内容（状況）'],b['Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "この問題はCAxで起きています。\n"
     ]
    }
   ],
   "source": [
    "ans = predicted_group(\"\"\"< 他部門のワークエリア利用申請について >\n",
    "\n",
    "昨日の19時頃に他部門のワークエリア利用申請を申請したが、\n",
    "\n",
    "まだワークエリアが利用できない状況。\n",
    "\n",
    "対応がいつ終わるか教えて欲しい。\n",
    "\n",
    "業務で必要なことなので、できるだけ早く対応して欲しい。\n",
    "\n",
    "\"\"\",b['Level1'],model4)\n",
    "print('この問題は' + ans + 'で起きています。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chat_Bot_Prot():    \n",
    "    while True:\n",
    "        message = input('どうかしましたか？')\n",
    "        if (message == '' or message == 'なにもない' or message == 'とくにない' or message =='さようなら' or message == 'ばいばい'):\n",
    "            print('そうですか、、、また何かあったら読んでくださいね・・・')\n",
    "            break\n",
    "        ans = predicted_group(message,b['Level1'],model4)\n",
    "        print('この問題は'+ ans + 'に関する問題ですね')\n",
    "\n",
    "        if ans == 'その他':\n",
    "            \"\"\"\n",
    "            分類した結果により処理を変える\n",
    "            備考：ここは関数化して分岐したほうが良い\n",
    "            \"\"\"\n",
    "            print('ヘルプデスクに問い合わせるのがいいと思います。')\n",
    "            print('ヘルプデスクを送りますか?')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "どうかしましたか？\n",
      "そうですか、、、また何かあったら読んでくださいね・・・\n"
     ]
    }
   ],
   "source": [
    "Chat_Bot_Prot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
